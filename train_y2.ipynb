{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('./train.csv').iloc[:, 1:]\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "# split data into X and y\n",
    "dfX = train.iloc[:,:-1]\n",
    "dfy = train.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.tail()\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train datasets 15119개\n",
    "* test datasets 565891개\n",
    "* 독립변수 12개\n",
    "* 종속변수 1개 Cover_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Elevation - Elevation in meters (높이 /meter 단위)\n",
    "* Aspect - Aspect in degrees azimuth (방위각)\n",
    "* Slope - Slope in degrees (기울기 각도 /도 단위)\n",
    "* Horizontal_Distance_To_Hydrology - Horz Dist to nearest surface water features (수원과의 수평거리)\n",
    "* Vertical_Distance_To_Hydrology - Vert Dist to nearest surface water features (수원과의 수직거리)\n",
    "* Horizontal_Distance_To_Roadways - Horz Dist to nearest roadway (길가와의 수평거리)\n",
    "* Hillshade_9am (0 to 255 index) - Hillshade index at 9am, summer solstice (오전 9시의 차양 / 0~255)\n",
    "* Hillshade_Noon (0 to 255 index) - Hillshade index at noon, summer solstice (정오시의 차양/ 0~255)\n",
    "* Hillshade_3pm (0 to 255 index) - Hillshade index at 3pm, summer solstice (오후 9시의 차양/ 0~255)\n",
    "* Horizontal_Distance_To_Fire_Points - Horz Dist to nearest wildfire ignition points (야생 산불 발화지점과의 수평거리)\n",
    "* Wilderness_Area (4 binary columns, 0 = absence or 1 = presence) - Wilderness area designation (황야 지대 /4종류 ) in Roosevelt National Forest of northern Colorado\n",
    "* Soil_Type (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation (토양 종류 / 40종류)\n",
    "* 토양종류와 황야 지대 카테고리별 설명은 https://www.kaggle.com/c/forest-cover-type-prediction/data 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종속 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cover_Type (7 types, integers 1 to 7) - Forest Cover Type designation- (산림 유형 / 7종류) (the predominant kind of tree cover)\n",
    "* 1 - Spruce/Fir\n",
    "* 2 - Lodgepole Pine\n",
    "* 3 - Ponderosa Pine\n",
    "* 4 - Cottonwood/Willow\n",
    "* 5 - Aspen\n",
    "* 6 - Douglas-fir\n",
    "* 7 - Krummholz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:,:20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:,20:40].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:,40:55].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Distanse_to_Hydrolody'] = (train['Horizontal_Distance_To_Hydrology']**2+train['Vertical_Distance_To_Hydrology']**2)**0.5\n",
    "test['Distanse_to_Hydrolody'] = (test['Horizontal_Distance_To_Hydrology']**2+test['Vertical_Distance_To_Hydrology']**2)**0.5\n",
    "\n",
    "train['Hydro_Fire_1'] = train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Fire_Points']\n",
    "test['Hydro_Fire_1'] = test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "train['Hydro_Fire_2'] = abs(train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Fire_Points'])\n",
    "test['Hydro_Fire_2'] = abs(test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Fire_Points'])\n",
    "\n",
    "train['Hydro_Road_1'] = abs(train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Roadways'])\n",
    "test['Hydro_Road_1'] = abs(test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Roadways'])\n",
    "\n",
    "train['Hydro_Road_2'] = abs(train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Roadways'])\n",
    "test['Hydro_Road_2'] = abs(test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Roadways'])\n",
    "\n",
    "train['Fire_Road_1'] = abs(train['Horizontal_Distance_To_Fire_Points']+train['Horizontal_Distance_To_Roadways'])\n",
    "test['Fire_Road_1'] = abs(test['Horizontal_Distance_To_Fire_Points']+test['Horizontal_Distance_To_Roadways'])\n",
    "\n",
    "train['Fire_Road_2'] = abs(train['Horizontal_Distance_To_Fire_Points']-train['Horizontal_Distance_To_Roadways'])\n",
    "test['Fire_Road_2'] = abs(test['Horizontal_Distance_To_Fire_Points']-test['Horizontal_Distance_To_Roadways'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From both train and test data\n",
    "train = train.drop(['Soil_Type7', 'Soil_Type15'], axis = 1)\n",
    "test = test.drop(['Soil_Type7', 'Soil_Type15'], axis = 1)\n",
    "\n",
    "# split data into X and y\n",
    "dfX = train.iloc[:,:-1]\n",
    "dfy = train.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "category_data = train.iloc[:, 10:]\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaled = RobustScaler().fit_transform(train.iloc[:,:10])\n",
    "standard_scaled = standard_scaler.fit_transform(train.iloc[:,:10])\n",
    "minmax_scaled = MinMaxScaler().fit_transform(train.iloc[:,:10])\n",
    "\n",
    "robust_data = pd.concat([pd.DataFrame(robust_scaled, columns = train.columns[:10]), category_data], axis=1)\n",
    "standard_data = pd.concat([pd.DataFrame(standard_scaled, columns = train.columns[:10]), category_data], axis=1)\n",
    "minmax_data = pd.concat([pd.DataFrame(minmax_scaled, columns = train.columns[:10]), category_data], axis=1)\n",
    "\n",
    "scaled_data_list = [robust_data, standard_data, minmax_data]\n",
    "roX = robust_data.iloc[  : , :-1 ]\n",
    "roy = robust_data.iloc[  : ,[-1] ]\n",
    "stanX = standard_data.iloc[  : , :-1 ]\n",
    "stany = standard_data.iloc[  : ,[-1] ]\n",
    "minX = minmax_data.iloc[  : , :-1 ]\n",
    "miny = minmax_data.iloc[  : ,[-1] ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation (K-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "def cv_score(model, train_data, train_target):\n",
    "    cv = KFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "    return cross_val_score(model, train_data, train_target, scoring='accuracy', cv= cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_clf =  XGBClassifier(n_estimators=500, max_depth = 10, learning_rate=0.03 ,objective='multi:softmax')\n",
    "gboost_clf = GradientBoostingClassifier(n_estimators=200)\n",
    "dt_clf = DecisionTreeClassifier(max_depth=10)\n",
    "extra_clf = ExtraTreesClassifier(n_estimators=200, max_depth=10)\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_score(xgb_clf, dfX, dfy))\n",
    "print(cv_score(gboost_clf, dfX, dfy))\n",
    "print(cv_score(dt_clf, dfX, dfy))\n",
    "print(cv_score(extra_clf, dfX, dfy))\n",
    "print(cv_score(rf_clf, dfX, dfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "#gboost_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "extra_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_names = ['XGB','Gradient','Decision','ExtraTree','RandomForest']\n",
    "importances = [ xgb_clf.feature_importances_, gboost_clf.feature_importances_, dt_clf.feature_importances_, extra_clf.feature_importances_, rf_clf.feature_importances_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "\n",
    "for color, importance in zip(['r','y','b','m','g'], importances):\n",
    "    plt.plot(range(54), importance, c= color)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(range(54))\n",
    "    ax.set_xticklabels(dfX.columns, fontdict={'fontsize': 9, 'rotation': 'vertical'})\n",
    "    plt.ylabel('Importance')\n",
    "plt.legend(model_names, loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_voting_clf = VotingClassifier(estimators=[('xgb', xgb_clf),('dt',dt_clf),\n",
    "                                          ('extra', extra_clf),('rf',rf_clf)], voting='soft')\n",
    "\n",
    "#h_voting_clf = VotingClassifier(estimators=[('xgb', xgb_clf),('gdboost',gboost_clf),('dt',dt_clf),\n",
    "#                                          ('extra', extra_clf),('rf',rf_clf)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(cv_score(s_voting_clf, dfX, dfy))\n",
    "#print(cv_score(h_voting_clf, dfX, dfy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfX, dfy, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target = ['class1', 'class2','class3','class4','class5','class6','class7' ]\n",
    "\n",
    "for clf in (xgb_clf, dt_clf, extra_clf, rf_clf, s_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    print (classification_report(y_test, y_pred, target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(n_jobs=-1,base_estimator=dt_clf, n_estimators=200, random_state=0)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "print(bag_clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "print (classification_report(y_test, y_pred, target_names=target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(df, count):\n",
    "    if count >= 10: ###cover type 1,2를 얼마만큼 중복생성할 것인지 결정.### \n",
    "        return df\n",
    "    add_1 = train.loc[train['Cover_Type'] == 1]\n",
    "    add_2 = train.loc[train['Cover_Type'] == 2]\n",
    "    new_df = pd.concat([add_1, add_2, df], axis=0)\n",
    "    return merge(new_df, count+1)\n",
    "\n",
    "new_train = merge(train, 0)\n",
    "\n",
    "#데이터 분리\n",
    "dfX = new_train.iloc[:, :-1]\n",
    "dfy = new_train.iloc[:, [-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "#X_res, y_res = ros.fit_sample(dfX, dfy)\n",
    "X_res, y_res = SMOTE(random_state=0).fit_sample(dfX, dfy)\n",
    "\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "#X, y = RandomOverSampler(random_state=0).fit_sample(dfX, dfy)\n",
    "#y_pred = plot_samples(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf = VotingClassifier(estimators=[('xgb', xgb_clf),('dt',dt_clf),\n",
    "                                          ('extra', extra_clf),('rf',rf_clf)], voting='soft')\n",
    "final_clf.fit(dfX, dfy)\n",
    "\n",
    "test_data = test.drop(\"Id\", axis=1).copy()\n",
    "prediction = final_clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Id\": test[\"Id\"],\n",
    "        \"Cover_type\": prediction\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission5.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_group = submission.groupby('Cover_type')\n",
    "submit_group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
