{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN_Model:\n",
    "\n",
    "    def __init__(self, sess, name, learning_rate = 0.01):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.device('/gpu:0'):\n",
    "            with tf.variable_scope(self.name):\n",
    "                # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "                # for testing\n",
    "                self.keep_prob = tf.placeholder(tf.float32)\n",
    "                nb_classes=7\n",
    "                # input place holders\n",
    "                self.X = tf.placeholder(tf.float32, [None, X_train.shape[1]])\n",
    "                self.Y = tf.placeholder(tf.float32, [None, 7])\n",
    "\n",
    "                W1 = tf.get_variable(\"W_1\", shape =[X_train.shape[1], 200], initializer=tf.contrib.layers.xavier_initializer())            \n",
    "                b1 = tf.Variable(tf.random_normal([200]), name = 'bias1')\n",
    "                L1 = tf.nn.relu(tf.matmul(self.X, W1) + b1)\n",
    "                L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "\n",
    "                W2 = tf.get_variable(\"W_2\", shape =[200, 400], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "                b2 = tf.Variable(tf.random_normal([400]), name = 'bias2')\n",
    "                L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "                L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "\n",
    "                W3 = tf.get_variable(\"W_3\", shape =[400, 400], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "                b3 = tf.Variable(tf.random_normal([400]), name = 'bias3')\n",
    "                L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "                L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "                W4 = tf.get_variable(\"W_4\", shape =[400, 200], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b4 = tf.Variable(tf.random_normal([200]), name = 'bias4')\n",
    "                L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "                L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "\n",
    "                W5 = tf.get_variable(\"W_5\", shape =[200, nb_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "                b5 = tf.Variable(tf.random_normal([nb_classes]), name = 'bias4')\n",
    "                self.logits = tf.matmul(L4, W5) + b5\n",
    "                '''\n",
    "                Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "                '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate= 0.001).minimize(self.cost)\n",
    "            self.predict_proba_ = tf.nn.softmax(self.logits)\n",
    "            prediction = tf.argmax(self.logits, 1)\n",
    "            correct_prediction = tf.equal(prediction, tf.argmax(self.Y, 1))\n",
    "\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "    \n",
    "    def fit(self, x_data, y_data, keep_prop=0.7):       \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        tf.reset_default_graph()\n",
    "        for step in range(2000):\n",
    "            cost, _ = self.sess.run([self.cost, self.optimizer], feed_dict={self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "        print('train finished')\n",
    "        return self\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "score : 0.8667(0.0084)\n",
      "----------------------------------------\n",
      "3/4\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "score : 0.8693(0.0101)\n",
      "----------------------------------------\n",
      "half\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "score : 0.8700(0.0084)\n",
      "----------------------------------------\n",
      "1/4\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "train finished\n",
      "score : 0.8681(0.0082)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "score_list = {}\n",
    "for name, ratio in zip(feature_select_names, feature_select):\n",
    "    print(name)\n",
    "    cv= KFold(5, shuffle = True, random_state = 42).split(standard_data)\n",
    "    acc=[]\n",
    "    for i, data in enumerate(cv):\n",
    "        X_train = standard_data.iloc[data[0]]\n",
    "        X_test = standard_data.iloc[data[1]]\n",
    "        y_train = train_target_onehot[data[0]]\n",
    "        y_test = train_target_onehot[data[1]]\n",
    "        tf.reset_default_graph()\n",
    "        # gpu 메모리할당\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "        nn = NN_Model(sess, 'nn'+ name +str(i))\n",
    "        nn.fit(X_train, y_train)\n",
    "        acc.append(nn.get_accuracy(X_test, y_test))\n",
    "    print('score : {:.4f}({:.4f})'.format(np.array(acc).mean(), np.array(acc).std()))\n",
    "    print('-' * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
